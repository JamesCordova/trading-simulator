# üìö Organizaci√≥n del Trabajo Final - Trading Simulator App
## Laboratorio de Calidad de Software

**Equipo:** 5 estudiantes  
**Duraci√≥n:** 10 d√≠as de trabajo efectivo  
**Aplicaci√≥n:** Trading Simulator (Next.js + Firebase)

---

## üìã √çNDICE

1. [Divisi√≥n Te√≥rica Ideal](#divisi√≥n-te√≥rica-ideal-5-personas)
2. [Divisi√≥n Real - Tareas Pendientes](#divisi√≥n-real---tareas-pendientes)
3. [Cronograma de Trabajo](#cronograma-de-trabajo)
4. [Documentaci√≥n a Entregar](#documentaci√≥n-a-entregar)
5. [Distribuci√≥n de Responsabilidades](#distribuci√≥n-de-responsabilidades)

---

## üéØ DIVISI√ìN TE√ìRICA IDEAL (5 Personas)

### Como si todos hubieran trabajado desde el inicio

### **Persona 1: Project Manager & QA Lead**
**Responsabilidades Te√≥ricas:**
- ‚úÖ Definici√≥n del alcance del proyecto
- ‚úÖ Planificaci√≥n inicial del plan de pruebas
- ‚úÖ Estrategia de testing (niveles, tipos, ambientes)
- ‚úÖ Coordinaci√≥n del equipo
- ‚úÖ Documentaci√≥n del Plan de Pruebas maestro
- ‚úÖ Integraci√≥n CI/CD con GitHub Actions

**Artefactos Te√≥ricos:**
- `TESTING_PLAN.md` - Plan maestro de pruebas
- `README.md` - Documentaci√≥n principal
- Configuraci√≥n de workflows (10 archivos .yml)
- Dashboard CI/CD

**Tiempo estimado:** 2-3 d√≠as

---

### **Persona 2: Test Automation Engineer (Unit & Integration)**
**Responsabilidades Te√≥ricas:**
- ‚úÖ Dise√±o e implementaci√≥n de pruebas unitarias (Jest)
- ‚úÖ Configuraci√≥n de cobertura de c√≥digo
- ‚úÖ Pruebas de componentes React
- ‚úÖ Integraci√≥n con SonarCloud
- ‚úÖ Mocks y fixtures para Firebase

**Artefactos Te√≥ricos:**
- 29 archivos de c√≥digo (componentes + tests)
- `jest.config.js`, `jest.setup.js`
- 15+ archivos de test (`*.test.js`, `*.test.jsx`)
- 88.28% de cobertura de c√≥digo
- 219 tests unitarios

**Tiempo estimado:** 3-4 d√≠as

---

### **Persona 3: Security & Performance Testing Specialist**
**Responsabilidades Te√≥ricas:**
- ‚úÖ Implementaci√≥n de OWASP ZAP DAST
- ‚úÖ Configuraci√≥n de K6 Performance Testing
- ‚úÖ Lighthouse para m√©tricas web
- ‚úÖ An√°lisis de vulnerabilidades
- ‚úÖ Optimizaci√≥n de performance

**Artefactos Te√≥ricos:**
- `k6/performance-test.js`
- `OWASP_ZAP.md` (9.7 KB)
- `K6_PERFORMANCE.md` (7.1 KB)
- `LIGHTHOUSE.md` (6 KB)
- Workflows: `owasp-zap.yml`, `k6-performance.yml`, `lighthouse.yml`
- Scripts de generaci√≥n de reportes

**Tiempo estimado:** 2-3 d√≠as

---

### **Persona 4: E2E Testing Engineer**
**Responsabilidades Te√≥ricas:**
- ‚úÖ Implementaci√≥n de Playwright E2E
- ‚úÖ Dise√±o de casos de prueba de sistema
- ‚úÖ Pruebas de flujos completos de usuario
- ‚úÖ Configuraci√≥n de ambientes de prueba
- ‚úÖ Datos de prueba y fixtures

**Artefactos Te√≥ricos:**
- `e2e/` folder (3 archivos de specs)
- `e2e/fixtures/mockData.ts`
- `playwright.config.ts`
- `PLAYWRIGHT.md` (9 KB)
- Workflow: `playwright.yml`

**Tiempo estimado:** 2-3 d√≠as

---

### **Persona 5: DevOps & Infrastructure**
**Responsabilidades Te√≥ricas:**
- ‚úÖ Configuraci√≥n Docker y Kubernetes
- ‚úÖ Deployment automatizado (Vercel)
- ‚úÖ Publicaci√≥n de reportes (GitHub Pages)
- ‚úÖ Configuraci√≥n de Firebase
- ‚úÖ Infraestructura CI/CD

**Artefactos Te√≥ricos:**
- `Dockerfile`, `.dockerignore`
- `DEPLOYMENT.md` (8 KB)
- `firebase.json`, `firestore.rules`
- Workflows: `docker-deploy.yml`, `vercel-deploy.yml`, `publish-reports.yml`
- Scripts de deployment

**Tiempo estimado:** 2 d√≠as

---

## üöÄ DIVISI√ìN REAL - TAREAS PENDIENTES

### Lo que REALMENTE falta por hacer (para completar el trabajo)

---

### **üë§ Persona 1: Introducci√≥n, Plan y Conclusiones**
**Tiempo estimado:** 6-8 horas

#### Tareas Pendientes:
**En TRABAJO_FINAL.md (documento consolidado):**

1. **Secci√≥n 1: Introducci√≥n** (1 hora)
   - [ ] Descripci√≥n del proyecto
   - [ ] Objetivos del plan de pruebas
   - [ ] Alcance (qu√© se prueba y qu√© no)

2. **Secci√≥n 2: Plan de Pruebas** (2 horas)
   - [ ] Estrategia por niveles (Unit, E2E, Security, Performance)
   - [ ] Herramientas utilizadas (tabla simple)
   - [ ] Ambientes de prueba
   - [ ] Cronograma ejecutado

3. **Secci√≥n 6: Conclusiones** (1 hora)
   - [ ] Objetivos cumplidos (checklist)
   - [ ] Lecciones aprendidas (3-5 puntos)
   - [ ] Recomendaciones futuras (3-5 puntos)

**En PRESENTACION_FINAL.pptx:**
- [ ] Slides 1-6: Introducci√≥n + Estrategia (2 horas)

**Entregables:**
- Secciones 1, 2, 6 de `TRABAJO_FINAL.md`
- Slides introductorios de presentaci√≥n

---

### **üë§ Persona 2: Requisitos y Pruebas Unitarias**
**Tiempo estimado:** 6-8 horas

#### Tareas Pendientes:
**En TRABAJO_FINAL.md:**

1. **Secci√≥n 3: Requisitos y Trazabilidad** (1 hora)
   - [ ] Lista de requisitos funcionales (14 items)
   - [ ] Lista de requisitos no funcionales (12 items)
   - [ ] Matriz de trazabilidad simple (tabla)

2. **Secci√≥n 4.1: Casos de Prueba Unitarias** (2 horas)
   - [ ] Resumen de 219 tests implementados
   - [ ] 5-10 casos de prueba ejemplo (formato simple)
   - [ ] M√©tricas: 88.28% cobertura
   - [ ] Herramientas: Jest + React Testing Library

**MANUAL_USUARIO.md:**
- [ ] Revisar y actualizar (1 hora)
  - Ya existe como `MANUAL_EJECUCION_TESTS.md`
  - Solo requiere revisi√≥n y ajustes menores

**En PRESENTACION_FINAL.pptx:**
- [ ] Slides 7-9: Pruebas Unitarias (2 horas)

**Entregables:**
- Secciones 3 y 4.1 de `TRABAJO_FINAL.md`
- `MANUAL_USUARIO.md` (revisi√≥n)
- Slides de unit tests

---

### **üë§ Persona 3: Seguridad y Performance**
**Tiempo estimado:** 6-8 horas

#### Tareas Pendientes:
**En TRABAJO_FINAL.md:**

1. **Secci√≥n 4.3: Casos de Prueba de Seguridad** (2 horas)
   - [ ] Configuraci√≥n OWASP ZAP
   - [ ] Vulnerabilidades buscadas (OWASP Top 10)
   - [ ] Resultados: 0 vulnerabilidades cr√≠ticas
   - [ ] 3-5 casos de prueba ejemplo
   - [ ] Security Rating: A

2. **Secci√≥n 4.4: Casos de Prueba de Performance** (2 horas)
   - [ ] Configuraci√≥n K6
   - [ ] Escenarios de carga (20, 50 usuarios)
   - [ ] Resultados: 46ms p95, <5% error rate
   - [ ] 3-5 casos de prueba ejemplo
   - [ ] M√©tricas alcanzadas vs objetivos

**En PRESENTACION_FINAL.pptx:**
- [ ] Slides 10-12: Security & Performance (2 horas)
  - Capturas de reportes OWASP ZAP
  - Capturas de reportes K6
  - Gr√°ficos de m√©tricas

**Entregables:**
- Secciones 4.3 y 4.4 de `TRABAJO_FINAL.md`
- Slides de security/performance

---

### **üë§ Persona 4: Pruebas E2E**
**Tiempo estimado:** 6-8 horas

#### Tareas Pendientes:
**En TRABAJO_FINAL.md:**

1. **Secci√≥n 4.2: Casos de Prueba E2E** (3 horas)
   - [ ] Configuraci√≥n Playwright
   - [ ] 3 specs implementadas: auth, dashboard, trading
   - [ ] 15 escenarios de prueba
   - [ ] 5-10 casos de prueba ejemplo detallados
   - [ ] Capturas de pantalla de ejecuci√≥n
   - [ ] Flujos de usuario end-to-end

**En PRESENTACION_FINAL.pptx:**
- [ ] Slides 13-14: Pruebas E2E (2 horas)
  - Screenshots de Playwright
  - Video o demo de tests corriendo
  
**Preparar Demo en Vivo:**
- [ ] Preparar demo de Playwright UI mode (1 hora)
- [ ] Ensayo de demo (30 min)

**Entregables:**
- Secci√≥n 4.2 de `TRABAJO_FINAL.md`
- Slides de E2E tests
- Demo en vivo preparada

---

### **üë§ Persona 5: Resultados y M√©tricas**
**Tiempo estimado:** 6-8 horas

#### Tareas Pendientes:
**En TRABAJO_FINAL.md:**

1. **Secci√≥n 5: Resultados de Ejecuci√≥n** (3 horas)
   - [ ] Tabla consolidada de m√©tricas alcanzadas vs objetivos
   - [ ] SonarCloud Quality Gate: PASSED
   - [ ] Capturas de pantalla de todos los reportes:
     - Coverage Report (88.28%)
     - CI/CD Dashboard
     - OWASP ZAP (0 cr√≠ticas)
     - K6 Performance (46ms p95)
     - Playwright results
   - [ ] Defectos encontrados (si hay alguno, sino poner 0)
   - [ ] An√°lisis de resultados

2. **Secci√≥n 7: Anexos** (30 min)
   - [ ] Links a reportes online (GitHub Pages)
   - [ ] Referencias y bibliograf√≠a

**En PRESENTACION_FINAL.pptx:**
- [ ] Slides 15-17: Resultados y M√©tricas (2 horas)
  - Dashboard CI/CD
  - Gr√°ficos de m√©tricas
  - Comparativa de objetivos
- [ ] Slide 20: Cr√©ditos y cierre (30 min)

**Entregables:**
- Secciones 5 y 7 de `TRABAJO_FINAL.md`
- Slides de resultados/m√©tricas
- Slide de cierre

---

### **üë• TODO EL EQUIPO: Presentaci√≥n Final**
**Tiempo estimado:** 2-3 horas (colaborativo)

#### Tareas Pendientes:
1. **Creaci√≥n de Presentaci√≥n** (2-3 horas - TODOS)
   - [ ] Persona 1: Slides de introducci√≥n, alcance y estrategia
   - [ ] Persona 2: Slides de pruebas unitarias y cobertura
   - [ ] Persona 3: Slides de seguridad y performance
   - [ ] Persona 4: Slides de pruebas E2E y sistema
   - [ ] Persona 5: Slides de m√©tricas y conclusiones
   - [ ] TODOS: Revisi√≥n y ajustes finales

2. **Preparaci√≥n de Demo** (1 hora - TODOS)
   - [ ] Ensayo de presentaci√≥n
   - [ ] Demostraci√≥n en vivo de tests
   - [ ] Mostrar reportes publicados
   - [ ] Q&A practice

3. **Distribuci√≥n de Secciones para Presentar**
   - Persona 1: Introducci√≥n y estrategia (5 min)
   - Persona 2: Pruebas unitarias (3 min)
   - Persona 3: Seguridad y performance (3 min)
   - Persona 4: Pruebas E2E (3 min)
   - Persona 5: M√©tricas y conclusiones (3 min)
   - TODOS: Q&A (3 min)

**Entregables:**
- `PRESENTACION_FINAL.pptx` (o Google Slides) - **COLABORATIVO**

---

## üìÖ CRONOGRAMA DE TRABAJO

### D√≠as 1-2: Planificaci√≥n y Dise√±o (Ya completado ‚úÖ)
- ‚úÖ Selecci√≥n de aplicaci√≥n
- ‚úÖ Revisi√≥n de requisitos
- ‚úÖ Definici√≥n de alcance
- ‚úÖ Dise√±o de estrategia

### D√≠as 3-7: Implementaci√≥n (Ya completado ‚úÖ)
- ‚úÖ Pruebas unitarias automatizadas (219 tests)
- ‚úÖ Pruebas E2E con Playwright (3 specs)
- ‚úÖ Pruebas de seguridad OWASP ZAP
- ‚úÖ Pruebas de performance K6
- ‚úÖ Configuraci√≥n CI/CD (10 workflows)

### **D√≠as 8-9: DOCUMENTACI√ìN (PENDIENTE) ‚ö†Ô∏è**

#### **D√≠a 8: Documentaci√≥n T√©cnica**
**Ma√±ana (4 horas):**
- Persona 1: Plan de Pruebas + Requisitos (3h)
- Persona 2: Casos de Prueba Unitarios (2h)
- Persona 3: Reporte de Seguridad (2h)
- Persona 4: Casos de Prueba E2E (2h)
- Persona 5: M√©tricas de Calidad (2h)

**Tarde (4 horas):**
- Persona 1: Reporte Ejecutivo (2h)
- Persona 2: An√°lisis de Cobertura (2h)
- Persona 3: Reporte de Performance (2h)
- Persona 4: Casos de Prueba Sistema (2h)
- Persona 5: Infraestructura (2h)

#### **D√≠a 9: Finalizaci√≥n y Revisi√≥n**
**Ma√±ana (4 horas):**
- Persona 1: Revisi√≥n general de documentos
- Persona 2: Manual de Ejecuci√≥n
- Persona 3: Casos No Funcionales
- Persona 4: Reporte de Defectos
- Persona 5: M√©tricas e Infraestructura

**Tarde (4 horas):**
- **TODO EL EQUIPO:** Revisi√≥n cruzada de documentos
- **TODO EL EQUIPO:** Inicio de presentaci√≥n (cada uno prepara sus slides)
- Correcciones y ajustes
- Consolidaci√≥n de entregables

### **D√≠a 10: Presentaci√≥n Final (PENDIENTE) ‚ö†Ô∏è**

**Ma√±ana (4 horas):**
- **TODO EL EQUIPO:** Finalizar presentaci√≥n colaborativa
- **TODO EL EQUIPO:** Ensayo completo de presentaci√≥n
- **TODO EL EQUIPO:** Preparar demostraci√≥n en vivo
- Asignar tiempos y transiciones

**Tarde:**
- **PRESENTACI√ìN FINAL** üéØ

---

## üì¶ DOCUMENTACI√ìN A ENTREGAR

### 1. Documentos Obligatorios del Curso

#### ‚úÖ Ya Existentes (parcialmente):
- [x] `README.md` - Documentaci√≥n general
- [x] `TESTING.md` - Gu√≠a de testing
- [x] `DEPLOYMENT.md` - Deployment
- [x] `K6_PERFORMANCE.md` - Performance
- [x] `OWASP_ZAP.md` - Seguridad
- [x] `PLAYWRIGHT.md` - E2E
- [x] `LIGHTHOUSE.md` - M√©tricas web

#### ‚ö†Ô∏è Pendientes de Crear (SIMPLIFICADO):
- [ ] `TRABAJO_FINAL.md` - **DOCUMENTO PRINCIPAL (TODO EN UNO)**
  - Incluye: Plan, Requisitos, Casos de Prueba, Resultados
- [ ] `MANUAL_USUARIO.md` - **Gu√≠a pr√°ctica de ejecuci√≥n**
- [ ] `PRESENTACION_FINAL.pptx` - **Diapositivas del equipo**

**NOTA:** En lugar de 14+ documentos separados, consolidamos todo en 2-3 archivos principales m√°s manejables para estudiantes.

### 2. Evidencias de Ejecuci√≥n

#### ‚úÖ Ya Disponibles:
- [x] Reportes HTML publicados en GitHub Pages
- [x] Coverage Report (88.28%)
- [x] CI/CD Dashboard
- [x] SonarCloud metrics
- [x] OWASP ZAP reports
- [x] K6 performance reports
- [x] Playwright test reports
- [x] GitHub Actions logs

---

## üë• DISTRIBUCI√ìN DE RESPONSABILIDADES

### Matriz de Responsabilidades (RACI)

| Documento/Tarea | P1 | P2 | P3 | P4 | P5 |
|-----------------|----|----|----|----|----| 
| Plan de Pruebas | **R** | C | C | C | I |
| Requisitos y Trazabilidad | **R** | C | I | I | I |
| Reporte Ejecutivo | **R** | C | C | C | C |
| Casos Prueba Unitarias | I | **R** | I | I | I |
| An√°lisis Cobertura | I | **R** | I | I | C |
| Manual Ejecuci√≥n | I | **R** | C | C | C |
| Reporte Seguridad | I | I | **R** | I | C |
| Reporte Performance | I | I | **R** | I | C |
| Casos No Funcionales | I | I | **R** | C | I |
| Casos Prueba E2E | I | C | I | **R** | I |
| Casos Prueba Sistema | I | C | I | **R** | I |
| Reporte Defectos | C | C | C | **R** | I |
| M√©tricas Calidad | C | C | C | C | **R** |
| Infraestructura | I | I | C | I | **R** |
| Presentaci√≥n Final | **R** | **R** | **R** | **R** | **R** |

**Leyenda:**
- **R** = Responsible (Responsable de crear)
- **C** = Consulted (Debe revisar y aportar)
- **I** = Informed (Debe estar informado)

---

## üéØ M√âTRICAS DEL PROYECTO (Estado Actual)

### Cobertura de Pruebas
- ‚úÖ **219 tests unitarios** implementados
- ‚úÖ **88.28% cobertura de c√≥digo**
- ‚úÖ **3 specs E2E** (Playwright)
- ‚úÖ **100% pruebas automatizadas**

### Infraestructura
- ‚úÖ **10 workflows CI/CD** configurados
- ‚úÖ **29 archivos de c√≥digo** con tests
- ‚úÖ **7 tipos de pruebas** diferentes
- ‚úÖ **4 reportes p√∫blicos** en GitHub Pages

### Calidad
- ‚úÖ **Quality Gate: PASSED** (SonarCloud)
- ‚úÖ **0 bugs cr√≠ticos**
- ‚úÖ **Security Rating: A**
- ‚úÖ **Maintainability: A**

---

## üìö RECURSOS Y BIBLIOGRAF√çA

### Referencias Utilizadas:
1. ISO/IEC/IEEE 29119 - Software Testing Standards
2. ISTQB Glossary - Testing terminology
3. Jest Documentation - https://jestjs.io/
4. Playwright Documentation - https://playwright.dev/
5. K6 Documentation - https://k6.io/docs/
6. OWASP Testing Guide - https://owasp.org/
7. Firebase Documentation - https://firebase.google.com/docs

### Herramientas Utilizadas:
- **Testing:** Jest, Playwright, K6, OWASP ZAP
- **CI/CD:** GitHub Actions
- **Quality:** SonarCloud, Lighthouse
- **Deployment:** Vercel, Docker
- **Version Control:** Git, GitHub

---

## üéì LECCIONES APRENDIDAS

### Lo que funcion√≥ bien ‚úÖ:
1. Automatizaci√≥n completa del pipeline CI/CD
2. Alta cobertura de c√≥digo (88.28%)
3. M√∫ltiples niveles de pruebas implementados
4. Reportes publicados y accesibles
5. Integraci√≥n con herramientas profesionales

### √Åreas de mejora ‚ö†Ô∏è:
1. Documentaci√≥n formal insuficiente
2. Falta de matriz de trazabilidad
3. Log de defectos no estructurado
4. Presentaci√≥n final pendiente
5. Divisi√≥n de trabajo desigual (1 persona hizo todo)

### Recomendaciones para futuros proyectos:
1. Documentar en paralelo con la implementaci√≥n
2. Asignar roles desde el d√≠a 1
3. Revisiones peri√≥dicas de avance
4. Usar plantillas de documentaci√≥n
5. Pair programming para transferencia de conocimiento

---

## üö¶ ESTADO ACTUAL Y PR√ìXIMOS PASOS

### ‚úÖ Completado (D√≠as 1-7):
- Implementaci√≥n t√©cnica al 100%
- Infraestructura CI/CD funcionando
- Pruebas automatizadas ejecut√°ndose
- Reportes siendo generados

### ‚ö†Ô∏è Pendiente (D√≠as 8-10):
- **Documentaci√≥n formal** (14 documentos)
- **Revisi√≥n cruzada** de entregables
- **Presentaci√≥n final** con demos
- **Consolidaci√≥n** de todo el trabajo

### üéØ Objetivo Final:
Entregar un trabajo completo que demuestre:
1. Comprensi√≥n del ciclo de vida de pruebas
2. Implementaci√≥n pr√°ctica de m√∫ltiples tipos de testing
3. Uso de herramientas profesionales
4. Documentaci√≥n acad√©mica formal
5. Capacidad de trabajo en equipo (aunque sea te√≥rico)

---

**Fecha de entrega:** [A definir seg√∫n cronograma del curso]  
**√öltima actualizaci√≥n:** ${new Date().toLocaleDateString('es-ES')}

